import os
import csv
import datetime
import time
import smtplib
import re
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.application import MIMEApplication
from email.header import Header
import google.generativeai as genai
from Bio import Entrez

# æ ¸å¿ƒä½œç”¨ï¼šæœ¬ä»£ç å®ç°äº†ä¸€ä¸ªå…¨è‡ªåŠ¨åŒ–çš„ç¥ç»ç§‘å­¦ç§‘ç ”æƒ…æŠ¥å·¥å…·ï¼Œæ¯æ—¥å®šæ—¶ä» PubMed æ£€ç´¢å¹¶ç­›é€‰ Alzheimer's Disease ä¸ Microglia é¢†åŸŸçš„æœ€æ–°é«˜åˆ†æ–‡çŒ®ï¼Œåˆ©ç”¨ Gemini AI ç”ŸæˆåŒ…å«â€œé‡ç‚¹æ·±åº¦è§£è¯»â€ä¸â€œå¿«é€Ÿæµè§ˆåˆ—è¡¨â€çš„ä¸“ä¸šä¸­æ–‡ç®€æŠ¥ï¼Œæœ€ç»ˆè‡ªåŠ¨ä»¥é‚®ä»¶å½¢å¼ï¼ˆé™„å¸¦æ•°æ® CSVï¼‰å‘é€ç»™ç”¨æˆ·ã€‚

# --- 1. å…¨å±€é…ç½® ---
Entrez.email = "julia_light@msn.cn"
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
SMTP_SERVER = os.getenv("SMTP_SERVER")
SMTP_PORT = os.getenv("SMTP_PORT")
EMAIL_SENDER = os.getenv("EMAIL_SENDER")
raw_password = os.getenv("EMAIL_PASSWORD")
EMAIL_RECEIVER = "julia_light@msn.cn"

if raw_password:
    EMAIL_PASSWORD = raw_password.replace(' ', '').replace('\xa0', '').strip()
else:
    EMAIL_PASSWORD = None

# æ£€ç´¢é…ç½®
SEARCH_WINDOW_DAYS = 3  # Day 0 - Day 3
TARGET_TOTAL_COUNT = 40 # æœ€ç»ˆä¿ç•™çš„ Top æ–‡çŒ®æ•°

# --- 2. æœŸåˆŠæ•°æ®åº“åŠ è½½ ---
def load_journal_db():
    db = {}
    csv_path = 'journals.csv'
    if not os.path.exists(csv_path):
        return {}
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader, None)
            for row in reader:
                if len(row) >= 2:
                    name = row[0].lower().strip()
                    try: if_val = float(row[1].strip())
                    except: if_val = 0.0
                    zone = row[2].strip() if len(row) > 2 else "?"
                    db[name] = {"if": if_val, "q": zone}
    except: pass
    return db

JOURNAL_DB = load_journal_db()

def get_journal_metrics(journal_name):
    if not journal_name: return 0.0, "?", False
    clean_name = journal_name.lower().split('(')[0].strip().replace('.', '')
    data = {"if": 0.0, "q": "?"}
    
    if clean_name in JOURNAL_DB:
        data = JOURNAL_DB[clean_name]
    elif clean_name.startswith("the ") and clean_name[4:] in JOURNAL_DB:
        data = JOURNAL_DB[clean_name[4:]]
        
    is_high = data["if"] > 10.0 or "Q1" in data["q"]
    return data["if"], data["q"], is_high

# --- 3. è¾…åŠ©æå–å‡½æ•° ---
def extract_country(text):
    if not text: return "Unknown"
    # ä¼˜å…ˆåŒ¹é…å¸¸è§ç§‘ç ”å¤§å›½
    countries = ["USA", "China", "UK", "Germany", "Japan", "Canada", "Australia", "France", "Italy", "Spain", "Netherlands", "Switzerland", "Korea", "Singapore"]
    text_u = text.upper()
    if "USA" in text_u or "UNITED STATES" in text_u: return "USA"
    if "CHINA" in text_u: return "China"
    if "UK" in text_u or "UNITED KINGDOM" in text_u: return "UK"
    
    for c in countries:
        if c.upper() in text_u: return c
    return "Global"

def format_author_details(author_entry):
    """æå–æ ¼å¼: å§“å [æœºæ„, å›½å®¶]"""
    if not author_entry: return "Unknown"
    
    last = author_entry.get('LastName', '')
    initials = author_entry.get('Initials', '')
    name = f"{last} {initials}"
    
    aff_info = author_entry.get('AffiliationInfo', [])
    if aff_info:
        raw_aff = aff_info[0].get('Affiliation', '')
        country = extract_country(raw_aff)
        # ç®€åŒ–æœºæ„å: å–é€—å·å‰çš„å†…å®¹ï¼Œæˆ–è€… University of X
        short_aff = raw_aff.split(',')[0]
        # ç®€å•çš„æ¸…æ´—é€»è¾‘
        short_aff = re.sub(r'Department of [A-Za-z\s]+', '', short_aff).strip()
        if len(short_aff) > 40: short_aff = short_aff[:37] + "..."
        
        return f"{name} [{short_aff}, {country}]"
    return name

# --- 4. PubMed æ ¸å¿ƒé€»è¾‘ ---
def build_search_queries():
    TERMS_AD = '("Alzheimer Disease"[Mesh] OR "Alzheimer\'s"[Title/Abstract] OR "Alzheimers"[Title/Abstract] OR "AD"[Title/Abstract] OR "Amyloid beta"[Title/Abstract] OR "Tau"[Title/Abstract])'
    TERMS_MICROGLIA = '("Microglia"[Mesh] OR "microglia"[Title/Abstract] OR "microglial"[Title/Abstract] OR "Neuroinflammation"[Title/Abstract] OR "DAM"[Title/Abstract] OR "TREM2"[Title/Abstract])'
    TERMS_NEURO_BROAD = '("Neuroscience"[Title/Abstract] OR "Neurology"[Title/Abstract] OR "Brain"[Title/Abstract] OR "CNS"[Title/Abstract])'

    return [
        f"({TERMS_AD} AND {TERMS_MICROGLIA})", # æ ¸å¿ƒ Q1-Q3
        f"{TERMS_AD}",                          # AD é«˜åˆ†
        f"({TERMS_MICROGLIA} AND {TERMS_NEURO_BROAD})" # Microglia é«˜åˆ†
    ]

def search_and_fetch_all():
    queries = build_search_queries()
    all_pmids = set()
    
    print(f"ğŸ” æ‰§è¡Œé«˜çº§æ£€ç´¢ (Window: {SEARCH_WINDOW_DAYS} days)...")
    for i, q in enumerate(queries):
        try:
            handle = Entrez.esearch(db="pubmed", term=q, retmax=100, sort="date", reldate=SEARCH_WINDOW_DAYS, datetype="pdat")
            ids = Entrez.read(handle)["IdList"]
            all_pmids.update(ids)
            time.sleep(1)
        except Exception as e:
            print(f"  Query {i} Error: {e}")

    unique_ids = list(all_pmids)
    if not unique_ids: return []

    print(f"ğŸ“¥ ä¸‹è½½ {len(unique_ids)} ç¯‡æ–‡çŒ®è¯¦æƒ…...")
    batch_size = 50
    final_papers = []
    
    for i in range(0, len(unique_ids), batch_size):
        try:
            handle = Entrez.efetch(db="pubmed", id=unique_ids[i:i+batch_size], rettype="xml", retmode="xml")
            data = Entrez.read(handle)
            handle.close()
            
            for article in data.get('PubmedArticle', []):
                try:
                    med = article['MedlineCitation']
                    art = med['Article']
                    
                    title = art.get('ArticleTitle', 'No Title')
                    journal = art.get('Journal', {}).get('Title', 'Unknown')
                    if_val, zone, is_high_impact = get_journal_metrics(journal)
                    
                    # æ—¥æœŸå¤„ç†
                    d = art.get('ArticleDate', [])
                    date_str = f"{d[0]['Year']}-{d[0]['Month']}-{d[0]['Day']}" if d else "Recent"
                    pub_status = "Online" if d else "Print"
                    
                    # ä½œè€…å¤„ç†
                    authors = art.get('AuthorList', [])
                    first_auth = format_author_details(authors[0]) if authors else "Unknown"
                    senior_auth = format_author_details(authors[-1]) if len(authors) > 1 else first_auth
                    
                    abstract = " ".join(art.get('Abstract', {}).get('AbstractText', []))
                    if not abstract: abstract = "No Abstract"
                    
                    # DOI & Types
                    doi = next((str(x) for x in med.get('Article', {}).get('ELocationID', []) if x.attributes.get('EIdType')=='doi'), "")
                    types = [t for t in art.get('PublicationTypeList', []) if "Journal" not in t and "Support" not in t]
                    type_str = ", ".join(types) if types else "Research"

                    # è¯„åˆ†ç­›é€‰é€»è¾‘
                    score = if_val
                    txt = (title + abstract).lower()
                    is_core = ("alzheimer" in txt or "amyloid" in txt) and ("microglia" in txt or "neuroinflammation" in txt)
                    
                    if is_core: score += 50
                    elif is_high_impact: score += 30
                    
                    # è¿‡æ»¤: éé«˜åˆ† ä¸” éæ ¸å¿ƒ ä¸” IF<3
                    if not is_high_impact and not is_core and if_val < 3.0:
                        continue

                    final_papers.append({
                        "PMID": str(med['PMID']),
                        "Title": title,
                        "Journal": journal,
                        "IF": if_val,
                        "Date": date_str,
                        "Status": pub_status,
                        "Type": type_str,
                        "First_Author": first_auth,
                        "Senior_Author": senior_auth,
                        "Abstract": abstract,
                        "DOI": doi,
                        "Score": score
                    })
                except: continue
        except: pass
            
    final_papers.sort(key=lambda x: x["Score"], reverse=True)
    return final_papers[:TARGET_TOTAL_COUNT]

# --- 5. Gemini AI åˆ†æ ---
def analyze_with_gemini(papers):
    if not GOOGLE_API_KEY: return "âŒ æ—  API Key"
    
    # å¼ºåˆ¶ä½¿ç”¨ Flash æ¨¡å‹
    model_name = 'gemini-flash-latest'
    
    # é…ç½®ç”Ÿæˆå‚æ•°ï¼šé™ä½ Temperature é˜²æ­¢å¹»è§‰
    generation_config = {
        "temperature": 0.2,
        "top_p": 0.95,
        "top_k": 64,
        "max_output_tokens": 8192,
    }
    
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel(model_name, generation_config=generation_config)
    
    # æ„å»ºè¾“å…¥æ•°æ®
    csv_block = "PMID | Title | Journal (IF) | First Author [Affiliation] | Senior Author [Affiliation] | Abstract\n"
    for p in papers:
        # æ‘˜è¦æˆªæ–­ä»¥é˜²è¶…é•¿ï¼Œä½†Flashé€šå¸¸æ²¡é—®é¢˜
        abs_clean = p['Abstract'][:1200]
        csv_block += f"{p['PMID']} | {p['Title']} | {p['Journal']} (IF:{p['IF']}) | {p['First_Author']} | {p['Senior_Author']} | {abs_clean}\n"

    prompt = f"""
# Role Assignment
ä½ æ˜¯ä¸€ä½æ‹¥æœ‰ 20 å¹´ç»éªŒçš„èµ„æ·±ç¥ç»ç§‘å­¦é¢†åŸŸç ”ç©¶å‘˜ï¼Œæ“…é•¿å¿«é€Ÿé˜…è¯»è‹±æ–‡å­¦æœ¯æ–‡çŒ®ï¼Œå¹¶å°†å…¶æ ¸å¿ƒä»·å€¼è½¬åŒ–ä¸ºé€»è¾‘ä¸¥å¯†ã€é€šä¿—æ˜“æ‡‚çš„ä¸­æ–‡æŠ€æœ¯ç®€æŠ¥ã€‚ä½ å¯¹ Alzheimer's diseaseã€Microglia ä»¥åŠå…¶ä»–ç¥ç»é€€è¡Œæ€§ç–¾ç—…é¢†åŸŸå‰æ²¿ç§‘ç ”çŸ¥è¯†ä¸æŠ€æœ¯æœ‰æ·±åˆ»çš„ç†è§£ã€‚

# Task
æˆ‘å°†æä¾›ä¸€æ‰¹æœ€æ–°çš„æ–‡çŒ®ä¿¡æ¯ï¼ˆCSVæ ¼å¼æ•°æ®ï¼‰ã€‚è¯·ä½ é˜…è¯»å¹¶åˆ†æè¿™äº›æ–‡çŒ®ï¼Œç”Ÿæˆä¸€ä»½ä¸­æ–‡â€œæ¯æ—¥ç§‘ç ”ç®€æŠ¥â€ã€‚

# Constraints
1. **å¿…é¡»ä½¿ç”¨ä¸­æ–‡è¿›è¡Œè¾“å‡º**ï¼Œä½†å¿…é¡»ä¿ç•™å¿…è¦çš„è‹±æ–‡ä¸“ä¸šæœ¯è¯­ï¼Œæˆ–åœ¨ä¸­æ–‡åæ‹¬å·å†…ä¿ç•™è‹±æ–‡ä¸“ä¸šæœ¯è¯­ï¼ˆä¾‹å¦‚ï¼šé¶ç‚¹è›‹ç™½å¦‚ TREM2ï¼Œæ¨¡å‹åç§°å¦‚ 5xFADï¼Œå…³é”®è¡¨å‹å¦‚ phagocytosis ç­‰ï¼‰ã€‚
2. **ä¸¥ç¦ç›´æ¥ç¿»è¯‘åŸæ–‡æ‘˜è¦**ï¼Œå¿…é¡»åŸºäºç†è§£è¿›è¡Œé‡è¿°å’Œæ¦‚æ‹¬ã€‚
3. **è¯­æ°”ä¿æŒå®¢è§‚ã€ä¸“ä¸š**ï¼Œé¿å…ä½¿ç”¨è¥é”€å¼å¤¸å¼ è¯æ±‡ã€‚
4. **"åˆ›æ–°ç‚¹"éƒ¨åˆ†å¿…é¡»å…·ä½“**ï¼ŒæŒ‡å‡ºè¯¥è®ºæ–‡è§£å†³äº†ä»€ä¹ˆå…·ä½“ç—›ç‚¹ï¼Œä¸ä»…æ˜¯ç½—åˆ—åŠŸèƒ½ã€‚
5. **å¿…é¡»ä¸€æ¬¡æ€§å®Œæ•´è¾“å‡º**ï¼šè¯·åˆç†åˆ†é…ç¯‡å¹…ï¼ŒåŠ¡å¿…åœ¨ä¸€æ¡å›å¤ä¸­åŒæ—¶åŒ…å«ã€ğŸŒŸ é‡ç‚¹å…³æ³¨ã€‘å’Œã€ğŸ“‚ å¿«é€Ÿæµè§ˆã€‘ä¸¤ä¸ªç‰ˆå—ã€‚

# Analysis Requirements

## Section 1: ğŸŒŸ é‡ç‚¹å…³æ³¨ (High Priority)
ç­›é€‰æ ‡å‡†ï¼šé«˜åˆ†æœŸåˆŠ (IF>10) æˆ– æœºåˆ¶åˆ›æ–°æå¼ºï¼ˆå¦‚å‘ç°æ–°é¶ç‚¹/æ–°é€šè·¯ï¼‰çš„ç ”ç©¶ã€‚
è¯·å¯¹æ¯ä¸€ç¯‡é‡ç‚¹æ–‡çŒ®æŒ‰ä»¥ä¸‹æ ¼å¼è¿›è¡Œæ·±è¯»ï¼š

- **æ ‡é¢˜**ï¼š(ä¸­æ–‡ç¿»è¯‘)
- **æœŸåˆŠ/IF**ï¼š(ä¿ç•™åŸå)
- **ğŸ‘¥ å…³é”®ä½œè€…**ï¼š
  - ä¸€ä½œï¼š(æå–è‡ª CSV First Author åˆ—ï¼Œä¿ç•™å§“åã€æœºæ„ã€å›½å®¶)
  - é€šè®¯ï¼š(æå–è‡ª CSV Senior Author åˆ—ï¼Œä¿ç•™å§“åã€æœºæ„ã€å›½å®¶)
- **ğŸ·ï¸ ç±»å‹**ï¼š[in vivoæœºåˆ¶ / in vitroæœºåˆ¶ / ç”Ÿä¿¡ / ä¸´åºŠ / ç»¼è¿°] (å¯å¤šé€‰ï¼Œå¦‚æ¶µç›–å¤šç§ä»¥+å·è¿æ¥)
- **ğŸ§ æ ¸å¿ƒå‘ç°**ï¼š(One-Liner äº®ç‚¹)
- **âœ¨ åˆ›æ–°ç‚¹**ï¼š(å…·ä½“æŒ‡å‡ºè¯¥è®ºæ–‡è§£å†³äº†ä»€ä¹ˆå…·ä½“ç—›ç‚¹ï¼Œæˆ–å¡«è¡¥äº†ä»€ä¹ˆç©ºç™½)
- **ğŸ§¬ å…³é”®æœºåˆ¶/é¶ç‚¹**ï¼š(æŒ‡æ˜ç ”ç©¶èšç„¦çš„å…·ä½“é€šè·¯ã€é¶ç‚¹ã€è¡¨å‹ã€ç»†èƒåŠŸèƒ½ç­‰ï¼ŒåŠç ”ç©¶ä½¿ç”¨çš„ä¸»è¦æ–¹æ³•)
- **ğŸ’¡ ç®€è¯„**ï¼š(ä¸“ä¸šè¯„ä»·å…¶ç§‘å­¦ä»·å€¼)

---

## Section 2: ğŸ“‚ å¿«é€Ÿæµè§ˆ (Quick Browse)
ç­›é€‰æ ‡å‡†ï¼šéªŒè¯æ€§ç ”ç©¶ã€ä½åˆ†æœŸåˆŠæˆ–çº¯ä¸´åºŠç»Ÿè®¡æ–‡ç« ã€‚
**è¯·åŠ¡å¿…ä»¥è¡¨æ ¼å½¢å¼å±•ç¤ºï¼Œä¸è¦åˆ†æ®µæè¿°ï¼š**

| åºå· | æ ‡é¢˜ (ä¸­æ–‡) | æœŸåˆŠ | ç±»å‹ | æ ¸å¿ƒå‘ç° (ä¸€å¥è¯) |
| :--- | :--- | :--- | :--- | :--- |
| 1 | ... | ... | ... | ... |

# Input Data
{csv_block}
"""
    
    print(f"ğŸ¤– è¯·æ±‚ Gemini ({model_name}) åˆ†æ {len(papers)} ç¯‡æ–‡çŒ®...")
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"âŒ AI åˆ†æç”Ÿæˆå¤±è´¥: {e}"

# --- 6. é‚®ä»¶å‘é€ ---
def send_email_report(content, csv_file):
    if not EMAIL_PASSWORD: return

    msg = MIMEMultipart()
    msg['From'] = EMAIL_SENDER
    msg['To'] = EMAIL_RECEIVER
    today = datetime.date.today()
    msg['Subject'] = Header(f"ğŸ§  NeuroBot æ·±åº¦ç®€æŠ¥ - {today}", 'utf-8')

    msg.attach(MIMEText(f"NeuroBot è‡ªåŠ¨åˆ†æå®Œæˆã€‚\n\n{content}", 'plain', 'utf-8'))

    try:
        with open(csv_file, "rb") as f:
            att = MIMEApplication(f.read(), Name=os.path.basename(csv_file))
            att['Content-Disposition'] = f'attachment; filename="{os.path.basename(csv_file)}"'
            msg.attach(att)
    except: pass

    try:
        server = smtplib.SMTP(SMTP_SERVER, int(SMTP_PORT))
        server.starttls()
        server.login(EMAIL_SENDER, EMAIL_PASSWORD)
        server.sendmail(EMAIL_SENDER, [EMAIL_RECEIVER], msg.as_string())
        server.quit()
        print("âœ… é‚®ä»¶å‘é€æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {e}")

# --- 7. ä¸»ç¨‹åº ---
def main():
    print(f"ğŸš€ NeuroBot V2 å¯åŠ¨ - {datetime.date.today()}")
    
    # 1. æ£€ç´¢ä¸æ¸…æ´—
    papers = search_and_fetch_all()
    if not papers:
        print("ğŸ“­ ä»Šæ—¥æ— ç¬¦åˆæ¡ä»¶æ•°æ®")
        return

    # 2. ç”Ÿæˆ CSV
    csv_name = f"NeuroBot_Data_{datetime.date.today()}.csv"
    headers = ["PMID", "Title", "Journal", "IF", "Date", "Status", "Type", "First_Author", "Senior_Author", "DOI", "Abstract", "Score"]
    with open(csv_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=headers)
        writer.writeheader()
        writer.writerows(papers)

    # 3. AI åˆ†æ
    report = analyze_with_gemini(papers)
    
    # 4. å‘é€
    send_email_report(report, csv_name)

if __name__ == "__main__":
    main()
