import os
import csv
import datetime
import time
import smtplib
from email.mime.text import MIMEText
from email.header import Header
import google.generativeai as genai
from Bio import Entrez

# --- 1. é…ç½®åŒºåŸŸ ---
Entrez.email = "julia_light@msn.cn"
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
SMTP_SERVER = os.getenv("SMTP_SERVER")
SMTP_PORT = os.getenv("SMTP_PORT")
EMAIL_SENDER = os.getenv("EMAIL_SENDER")
raw_password = os.getenv("EMAIL_PASSWORD")
EMAIL_RECEIVER = "julia_light@msn.cn"

# ğŸ”´ ç­–ç•¥è°ƒæ•´åŒº
# æ¯å¤©åªæ·±åº¦åˆ†æå¤šå°‘ç¯‡ï¼Ÿ(å»ºè®®ä¸è¶…è¿‡15ç¯‡ä»¥é¿å…429é”™è¯¯)
MAX_AI_ANALYSIS_NEURO = 10 
MAX_AI_ANALYSIS_TCM = 3
# æ£€ç´¢æœ€è¿‘å‡ å¤©ï¼Ÿ(å»ºè®®2-3å¤©ï¼Œé¿å…0ç»“æœ)
SEARCH_WINDOW_DAYS = 2 

if raw_password:
    EMAIL_PASSWORD = raw_password.replace(' ', '').replace('\xa0', '').strip()
else:
    EMAIL_PASSWORD = None

# --- 2. åŠ¨æ€æœŸåˆŠæ•°æ®åº“ ---
def load_journal_db():
    db = {}
    csv_path = 'journals.csv'
    if not os.path.exists(csv_path):
        return {}
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader, None)
            for row in reader:
                if len(row) >= 2:
                    name = row[0].lower().strip()
                    db[name] = {"if": row[1].strip(), "q": row[2].strip() if len(row) > 2 else "?"}
    except:
        pass
    return db

JOURNAL_DB = load_journal_db()

def get_journal_metrics(journal_name):
    if not journal_name: return "N/A", "N/A"
    clean_name = journal_name.lower().split('(')[0].strip()
    if clean_name in JOURNAL_DB:
        return JOURNAL_DB[clean_name]['if'], JOURNAL_DB[clean_name]['q']
    if clean_name.startswith("the "):
        alt = clean_name[4:].strip()
        if alt in JOURNAL_DB: return JOURNAL_DB[alt]['if'], JOURNAL_DB[alt]['q']
    return "N/A", ""

def setup_gemini():
    if not GOOGLE_API_KEY:
        print("âŒ æ—  API KEY")
        return None
    genai.configure(api_key=GOOGLE_API_KEY)
    return genai.GenerativeModel('gemini-flash-latest')

def search_pubmed_ids(query, max_results):
    print(f"ğŸ” æ£€ç´¢(è¿‘{SEARCH_WINDOW_DAYS}å¤©): {query[:30]}...")
    try:
        # âœ… å…³é”®ä¿®æ”¹ï¼šreldate ä½¿ç”¨é…ç½®å˜é‡
        handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results, sort="date", reldate=SEARCH_WINDOW_DAYS, datetype="pdat")
        record = Entrez.read(handle)
        handle.close()
        return record["IdList"]
    except Exception as e:
        print(f"âš ï¸ æ£€ç´¢å¤±è´¥: {e}")
        return []

def fetch_and_parse(id_list, tag_label):
    if not id_list: return []
    print(f"ğŸ“¥ [{tag_label}] ä¸‹è½½ {len(id_list)} ç¯‡...")
    try:
        handle = Entrez.efetch(db="pubmed", id=id_list, rettype="xml", retmode="xml")
        xml_data = Entrez.read(handle)
        handle.close()
    except:
        return []

    parsed_list = []
    for article in xml_data.get('PubmedArticle', []):
        try:
            art = article.get('MedlineCitation', {}).get('Article', {})
            title = art.get('ArticleTitle')
            if not title: continue
            
            abstract = " ".join(art.get('Abstract', {}).get('AbstractText', [])) or "ã€æ— æ‘˜è¦ã€‘"
            j_name = art.get('Journal', {}).get('Title', 'Unknown')
            if_val, zone = get_journal_metrics(j_name)
            
            try: sort_score = float(if_val)
            except: sort_score = -1.0
            
            d = art.get('ArticleDate', [])
            date_str = f"{d[0]['Year']}-{d[0]['Month']}-{d[0]['Day']}" if d else "Recent"
            
            authors = art.get('AuthorList', [])
            auth = "Unknown"
            if authors:
                f = authors[0]
                aff = f['AffiliationInfo'][0]['Affiliation'] if f.get('AffiliationInfo') else ""
                flag = "[ğŸ‡¨ğŸ‡³CN]" if "China" in aff else ("[ğŸ‡ºğŸ‡¸US]" if "USA" in aff else "")
                auth = f"{f.get('LastName')} {flag}"

            parsed_list.append({
                "title": title, "abstract": abstract, "journal": j_name,
                "if": if_val, "zone": zone, "sort_score": sort_score,
                "date": date_str, "author": auth, "tag": tag_label
            })
        except: continue
    return parsed_list

def analyze_with_ai(model, paper):
    print(f"ğŸ¤– AI é˜…è¯»: {paper['title'][:20]}...")
    
    prompt = f"""
    ä½ æ˜¯ç¥ç»ç§‘å­¦ä¸“å®¶ã€‚è¯·ç”¨ä¸­æ–‡ç®€è¿°è¿™ç¯‡æ–‡çŒ®ã€‚
    æ ‡é¢˜: {paper['title']}
    æ‘˜è¦: {paper['abstract']}
    
    è¾“å‡ºæ ¼å¼(Markdown):
    ### {paper['tag']} | {paper['title']}
    > ğŸ“… {paper['date']} | ğŸ“– {paper['journal']} (IF:{paper['if']}) | ğŸ‘¤ {paper['author']}
    - **ğŸ·ï¸ ç±»å‹**: [ç»¼è¿°/å®éªŒ/ä¸´åºŠ]
    - **ğŸ§ æ ¸å¿ƒ**: (ä¸€å¥è¯ç»“è®º,å«æ•°æ®)
    - **ğŸ”¬ æœºåˆ¶**: (é€šè·¯/é¶ç‚¹)
    """
    
    # âœ… å…³é”®ä¿®æ”¹ï¼šæ›´ç¨³å¥çš„é‡è¯•é€»è¾‘
    for attempt in range(3):
        try:
            res = model.generate_content(prompt)
            # æˆåŠŸåï¼Œå¼ºåˆ¶ä¼‘æ¯ 15 ç§’ (é¿å…RPMè¶…é™)
            time.sleep(15) 
            return res.text.replace('\xa0', ' ')
        except Exception as e:
            err_str = str(e)
            if "429" in err_str:
                print(f"âš ï¸ è§¦å‘é™æµ (429)ï¼Œå†·å´ 60ç§’...")
                time.sleep(60) # ç½šç«™ 60s
            else:
                print(f"âš ï¸ å…¶ä»–é”™è¯¯: {e}")
                time.sleep(5)
    
    return f"âŒ {paper['title']} (åˆ†æå¤±è´¥)\n\n"

def format_simple_list(papers):
    """ä¸ç»è¿‡AIï¼Œåªåˆ—å‡ºæ ‡é¢˜ï¼ŒèŠ‚çœé¢åº¦"""
    if not papers: return ""
    txt = "\n#### ğŸ“‹ å…¶ä»–æ–°æ”¶å½•æ–‡çŒ® (ä»…åˆ—è¡¨)\n"
    for p in papers:
        txt += f"- **{p['date']}** | {p['title']} | *{p['journal']}*\n"
    return txt + "\n"

def main():
    model = setup_gemini()
    
    # Neuro
    neuro_ids = search_pubmed_ids('(Alzheimer\'s disease[Title/Abstract] AND (microglia[Title/Abstract] OR neuroinflammation[Title/Abstract]))', 30)
    neuro_papers = fetch_and_parse(neuro_ids, "ğŸ§ ")
    neuro_papers.sort(key=lambda x: x['sort_score'], reverse=True)
    
    # TCM
    tcm_ids = search_pubmed_ids('((Traditional Chinese Medicine[Title/Abstract] OR Herbal[Title/Abstract] OR Acupuncture[Title/Abstract]) AND (Alzheimer[Title/Abstract] OR Brain[Title/Abstract]))', 10)
    tcm_papers = fetch_and_parse(tcm_ids, "ğŸŒ¿")
    tcm_papers.sort(key=lambda x: x['sort_score'], reverse=True)

    if not neuro_papers and not tcm_papers:
        print("ğŸ“­ ä»Šæ—¥æ— æ•°æ®")
        return

    # === åˆ†çº§å¤„ç† ===
    # 1. ç²¾é€‰ (AIåˆ†æ)
    top_neuro = neuro_papers[:MAX_AI_ANALYSIS_NEURO]
    top_tcm = tcm_papers[:MAX_AI_ANALYSIS_TCM]
    
    # 2. åˆ—è¡¨ (ä»…æ ‡é¢˜)
    rest_neuro = neuro_papers[MAX_AI_ANALYSIS_NEURO:]
    rest_tcm = tcm_papers[MAX_AI_ANALYSIS_TCM:]

    content = f"ğŸ§  NeuroBot æ—¥æŠ¥ ({datetime.date.today()})\n"
    content += f"â±ï¸ æ£€ç´¢èŒƒå›´: è¿‡å» {SEARCH_WINDOW_DAYS} å¤© | ğŸ“Š æ”¶å½•: {len(neuro_papers)+len(tcm_papers)} ç¯‡\n\n"

    # TCM æ¿å—
    if top_tcm:
        content += "--- ğŸŒ¿ TCM ç²¾é€‰ ---\n\n"
        for p in top_tcm: content += analyze_with_ai(model, p)
        content += format_simple_list(rest_tcm)

    # Neuro æ¿å—
    if top_neuro:
        content += "\n--- ğŸ§  Neuro ç²¾é€‰ ---\n\n"
        for p in top_neuro: content += analyze_with_ai(model, p)
        content += format_simple_list(rest_neuro)

    send_email(f"NeuroBotæ—¥æŠ¥ - {datetime.date.today()}", content)

if __name__ == "__main__":
    main()
